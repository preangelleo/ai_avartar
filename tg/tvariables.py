# -*- coding: utf-8 -*-
from prompt_template import *
from bot_init import *

owner_parameters_dict = get_owner_parameters()

if place_holder:
    # Get the environment variables
    USER_AVATAR_NAME = owner_parameters_dict.get('USER_AVATAR_NAME')
    UBUNTU_SERVER_IP_ADDRESS = owner_parameters_dict.get('UBUNTU_SERVER_IP_ADDRESS')
    DOMAIN_NAME = owner_parameters_dict.get('DOMAIN_NAME')
    OPENAI_API_KEY = owner_parameters_dict.get('OPENAI_API_KEY')
    BOT_TOKEN = owner_parameters_dict.get('BOT_TOKEN')
    BOT_USERNAME = owner_parameters_dict.get('BOT_USERNAME')
    USER_TELEGRAM_LINK = owner_parameters_dict.get('USER_TELEGRAM_LINK')
    BOTOWNER_CHAT_ID = owner_parameters_dict.get('BOTOWNER_CHAT_ID')
    BOTCREATER_CHAT_ID = owner_parameters_dict.get('BOTCREATER_CHAT_ID')
    REPLICATE_KEY = owner_parameters_dict.get('REPLICATE_KEY')
    STABILITY_API_KEY = owner_parameters_dict.get('STABILITY_API_KEY')
    OPENAI_MODEL = owner_parameters_dict.get('OPENAI_MODEL')
    WOLFRAM_ALPHA_APPID = owner_parameters_dict.get('WOLFRAM_ALPHA_APPID')
    MAX_CONVERSATION_PER_MONTH = owner_parameters_dict.get('MAX_CONVERSATION_PER_MONTH')
    PINECONE_FREE = owner_parameters_dict.get('PINECONE_FREE')
    PINECONE_FREE_ENV = owner_parameters_dict.get('PINECONE_FREE_ENV')
    INFURA_KEY = owner_parameters_dict.get('INFURA_KEY')
    CMC_PA_API = owner_parameters_dict.get('CMC_PA_API')
    FINNHUB_API = owner_parameters_dict.get('FINNHUB_API')
    ETHERSCAN_API = owner_parameters_dict.get('ETHERSCAN_API')
    MORALIS_API = owner_parameters_dict.get('MORALIS_API')
    MORALIS_ID = owner_parameters_dict.get('MORALIS_ID')
    MORALIS_APP_ID = owner_parameters_dict.get('MORALIS_APP_ID')
    DEBANK_API = owner_parameters_dict.get('DEBANK_API')
    MONTHLY_FEE = float(owner_parameters_dict.get('MONTHLY_FEE'))
    REFILL_TEASER = owner_parameters_dict.get('REFILL_TEASER')

    # Êü•ÁúãÂΩìÂâçÁõÆÂΩïÂπ∂ÂÜ≥ÂÆö TELEGRAM_BOT_RUNNING ÁöÑÂÄº
    TELEGRAM_BOT_RUNNING = BOT_TOKEN
    TELEGRAM_BOT_NAME = BOT_USERNAME
    BOT_OWNER_LIST = [BOTOWNER_CHAT_ID, BOTCREATER_CHAT_ID]

    openai.api_key = OPENAI_API_KEY
    os.environ["OPENAI_API_KEY"] = OPENAI_API_KEY

    ELEVENLABS_API = os.getenv("ELEVEN_API_KEY")
    BING_SEARCH_API_KEY = os.getenv("BING_SEARCH_API")
    STABILITY_URL = f"https://api.stability.ai/v1/"

    ETHERSCAN_WALLET_URL_PREFIX = 'https://etherscan.io/address/'
    ETHERSCAN_TX_URL_PREFIX = 'https://etherscan.io/tx/'
    ETHERSCAN_TOKEN_URL_PREFIX = 'https://etherscan.io/token/'

    BOTCREATER_TELEGRAM_HANDLE = '@laogege6'

    # Telegram base URL
    telegram_base_url = "https://api.telegram.org/bot" + TELEGRAM_BOT_RUNNING + "/"    
    # initialize pinecone
    pinecone.init(api_key=PINECONE_FREE,  environment=PINECONE_FREE_ENV)

    os.environ["WOLFRAM_ALPHA_APPID"] = os.getenv('WOLFRAM_ALPHA_APPID')
    wolfram = WolframAlphaAPIWrapper()
    wikipedia = WikipediaAPIWrapper()

    embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)
    llm = ChatOpenAI(model_name="gpt-4", temperature=0, openai_api_key=OPENAI_API_KEY)

    avatar_png = 'files/images/512.png'
    avatar_command_png = 'files/images/avatar_command.png'
    avatar_create = f"Â¶ÇÊûúÊÇ®‰πüÂ∏åÊúõÊã•Êúâ‰∏Ä‰∏™ÂÉè @{TELEGRAM_BOT_NAME} ËøôÊ†∑ÁöÑ <AIÂàÜË∫´> Êù•ÊúçÂä°ÊÇ®ÁöÑÊúãÂèã‰ª¨, ‰ª•ÊÇ®ÁöÑËØ≠Ê∞îÈô™‰ªñ‰ª¨/Â•π‰ª¨ËÅäÂ§©, Â∏Æ‰ªñ‰ª¨ÂÆåÊàê OpenAI Â§ßËØ≠Ë®ÄÊ®°ÂûãÂèØ‰ª•ÂÅöÁöÑ‰∏ÄÂàá‰ªªÂä°, ÂèØ‰ª•ÁÇπÂáª /more_information ‰∫ÜËß£, ÈùûËØöÂãøÊâ∞, Ë∞¢Ë∞¢! üòã"
    avatar_more_information = "<AIÂàÜË∫´> ÁîµÊä•Êú∫Âô®‰∫∫Áî±ÈÖ∑Áà± Python ÁöÑËÄÅÂì•Âì• @laogege6 Âà©Áî®‰∏ö‰ΩôÊó∂Èó¥ÂºÄÂèëÂàõÈÄ† üòä:\n\n- ÊäÄÊúØÊúçÂä°Ë¥π: 100ÁæéÈáë/Êúà;\n- ÊîØÊåÅ USDT Á≠âÂêÑÁßç‰ªòÊ¨æÊñπÂºè;\n- ÈúÄË¶ÅÊÇ®Êèê‰æõËá™Â∑±ÁöÑ OpenAI API;\n- ÈúÄË¶ÅÊÇ®Âú® @BotFather ÂºÄÈÄöÊú∫Âô®‰∫∫Ë¥¶Âè∑;\n- ÊÇ®ÂèØ‰ª•ÈöèÊó∂‰øÆÊîπ <AIÂàÜË∫´> ÁöÑ‰∫∫ËÆæËÉåÊôØ;\n- ÊÇ®ÂèØ‰ª•Ëá™Áî±‰øÆÊîπ <AIÂàÜË∫´> ÁöÑËØ≠Ë∞ÉËØ≠Ê∞î.\n\nËØ¶ÊÉÖÈÇÆ‰ª∂Âí®ËØ¢:\nadmin@leonardohuang.com"

def convert_to_local_timezone(timestamp, local_time_zone='America/Los_Angeles'):
    utc_timestamp = datetime.strptime(timestamp, '%Y-%m-%dT%H:%M:%S.%fZ')
    utc_timezone = pytz.timezone('UTC')
    local_timezone = pytz.timezone(local_time_zone)  # Replace with your local timezone

    local_timestamp = utc_timezone.localize(utc_timestamp).astimezone(local_timezone)
    formatted_timestamp = local_timestamp.strftime('%Y-%m-%d %H:%M:%S')

    return formatted_timestamp

def bing_search(query, mkt='en-US'):
    '''
    This sample makes a call to the Bing Web Search API with a query and returns relevant web search.
    Documentation: https://docs.microsoft.com/en-us/bing/search-apis/bing-web-search/overview
    '''
    endpoint = "https://api.bing.microsoft.com/v7.0/search"

    # Construct a request
    params = {'q': query, 'mkt': mkt}
    headers = {'Ocp-Apim-Subscription-Key': BING_SEARCH_API_KEY}

    # Call the API
    try:
        response = requests.get(endpoint, headers=headers, params=params)
        response.raise_for_status()

        folder = 'files/bing_search'
        if not os.path.exists(folder): os.makedirs(folder)
        query = query.lower()

        query_name = query.replace(',', '')
        query_name = query_name.replace(' ', '_')
        query_name = query_name.replace('?', '')
        query_name = query_name.replace('!', '')
        query_name = query_name.replace('(', '')
        query_name = query_name.replace(')', '')
        query_name = query_name.replace('\'', '')
        query_name = query_name.replace('\"', '')
        query_name = query_name.replace(':', '')
        query_name = query_name.replace(';', '')
        query_name = query_name.replace('+', '')
        query_name = query_name.replace('=', '')
        query_name = query_name.replace('*', '')
        query_name = query_name.replace('&', '')
        query_name = query_name.replace('%', '')
        query_name = query_name.replace('$', '')
        query_name = query_name.replace('#', '')
        query_name = query_name.replace('@', '')
        query_name = query_name.replace('~', '')
        query_name = query_name.replace('`', '')
        query_name = query_name.replace('^', '')
        query_name = query_name.replace('/', '')
        query_name = query_name.replace('\\', '')
        query_name = query_name.replace('|', '')
        query_name = query_name.replace('<', '')
        query_name = query_name.replace('>', '')
        query_name = query_name.replace('[', '')
        query_name = query_name.replace(']', '')
        query_name = query_name.replace('{', '')
        query_name = query_name.replace('}', '')
        query_name = query_name.replace('‚Äô', '')
        query_name = query_name.replace('‚Äò', '')
        query_name = query_name.replace('‚Äú', '')
        query_name = query_name.replace('‚Äù', '')

        file_path = f'{folder}/{str(datetime.now().strftime("%Y-%m-%d %H:%M:%S").split()[0])}-{query_name[:66]}.txt'
        if os.path.isfile(file_path): os.remove(file_path)

        with open(file_path, 'a') as file:
            for k, v in response.json().items():
                if k in ['news']:
                    file.write(k.upper() + '\n\n')
                    if type(v) is not dict:
                        continue
                    for a, b in v.items():
                        if a in ['value']:
                            for c in b:
                                if c.get('name'):
                                    file.write('name: '.upper() +
                                               c.get('name') + '\n')
                                if c.get('description'):
                                    file.write('snippet: '.upper() +
                                               c.get('description') + '\n')
                                if c.get('url'):
                                    file.write('url: '.upper() +
                                               c.get('url') + '\n')
                                if c.get('image'):
                                    file.write(
                                        'image: '.upper() + c.get('image').get('contentUrl').split('?')[0] + '\n')
                                if c.get('datePublished'):
                                    file.write('DATE: '.upper() + c.get('datePublished').split('T')[
                                               0] + ' ' + c.get('datePublished').split('T')[1].split('.')[0] + '\n')
                                file.write('\n')
                    file.write('\n')

                if k in ['videos']:
                    file.write(k.upper() + '\n\n')
                    if type(v) is not dict:
                        continue
                    for a, b in v.items():
                        if a in ['value']:
                            for c in b:
                                if c.get('name'):
                                    file.write('name: '.upper() +
                                               c.get('name') + '\n')
                                if c.get('description'):
                                    file.write('snippet: '.upper() +
                                               c.get('description') + '\n')
                                if c.get('contentUrl'):
                                    file.write('url: '.upper() +
                                               c.get('contentUrl') + '\n')
                                if c.get('datePublished'):
                                    file.write('DATE: '.upper() + c.get('datePublished').split('T')[
                                               0] + ' ' + c.get('datePublished').split('T')[1].split('.')[0] + '\n')
                                file.write('\n')
                    file.write('\n')

                if k in ['webPages']:
                    file.write(k.upper() + '\n\n')
                    if type(v) is not dict:
                        continue
                    for a, b in v.items():
                        if a in ['value']:
                            for c in b:
                                if c.get('name'):
                                    file.write('name: '.upper() +
                                               c.get('name') + '\n')
                                if c.get('snippet'):
                                    file.write('snippet: '.upper() +
                                               c.get('snippet') + '\n')
                                if c.get('url'):
                                    file.write('url: '.upper() +
                                               c.get('url') + '\n')
                                if c.get('dateLastCrawled'):
                                    file.write('DATE: '.upper() + c.get('dateLastCrawled').split('T')[
                                               0] + ' ' + c.get('dateLastCrawled').split('T')[1].split('.')[0] + '\n')
                                file.write('\n')
                    file.write('\n')
            return file_path

    except Exception as e:
        print(f"ERROR: Bing search failed: {e}")
        return    
    
def format_number(num):
    if not num:
        return 0
    if type(num) is dict:
        print(num)
        return 0
    if type(num) is not str and not float and not int:
        return num
    if type(num) is str:
        try:
            num = float(num)
        except Exception as e:
            return num
    positive = 1 if num >= 0 else -1
    num = abs(num)
    if num >= 1000:
        num = int(num)
        num = num * positive
        num = format(num, ',')
        return num
    if num >= 100:
        num = int(num)
        return num * positive
    if num >= 1:
        num = round(num, 2)
        return num * positive
    if num < 0.0001:
        if debug:
            print("DEBUG: format_number() no_need_to_change: ", num)
        return num * positive
    if num < 1:
        after_0_num = str(num).split('.')[-1]
        list_number = list(after_0_num)
        for i in range(len(list_number)):
            if int(list_number[i]) != 0:
                zero_num = i
                break
        num = round(num, zero_num + 3)
        return num * positive

def hash_md5(content):
    hashed_content = hashlib.md5(str(content).encode('utf-8')).hexdigest()
    return hashed_content

def hash_sha256(content):
    hashed_content = hashlib.sha256(str(content).encode('utf-8')).hexdigest()
    return hashed_content

def is_english(text):
    result = chardet.detect(text.encode())
    encoding = result['encoding']
    if encoding == 'ascii': return True
    lang = detect(text)
    if lang == 'en': return True

def markdown_wallet_address(wallet_address):
    markdown_address = f'[{wallet_address[:6]}...{wallet_address[-7:]}]({ETHERSCAN_WALLET_URL_PREFIX}{wallet_address})'
    return markdown_address

def markdown_transaction_hash(hash_tx):
    markdown_tx = f'[{hash_tx[:6]}......{hash_tx[-7:]}]({ETHERSCAN_TX_URL_PREFIX}{hash_tx})'
    return markdown_tx

def markdown_token_address(token_address):
    markdown_token = f'[{token_address[:6]}...{token_address[-7:]}]({ETHERSCAN_TOKEN_URL_PREFIX}{token_address})'
    return markdown_token

def markdown_tokentnxs(address):
    markdown_token = f'[{address[:6]}...{address[-7:]}]({ETHERSCAN_TOKEN_URL_PREFIX}{address}#tokentxns)'
    return markdown_token

def chat_gpt_regular(prompt, chatgpt_key=OPENAI_API_KEY, use_model=OPENAI_MODEL):
    if not prompt: return

    # Load your API key from an environment variable or secret management service
    openai.api_key = chatgpt_key

    response = openai.ChatCompletion.create(
        model=use_model,
        messages=[
            {"role": "user", "content": prompt}
        ]
    )

    reply = response['choices'][0]['message']['content']
    reply = reply.strip('\n').strip()

    return reply

def chat_gpt_full(prompt, system_prompt='', user_prompt='', assistant_prompt='', dynamic_model='', chatgpt_key=''):
    if not prompt:
        return

    if not dynamic_model:
        dynamic_model = "gpt-3.5-turbo"
    if not system_prompt:
        system_prompt = "You are a very knowledgeable sage, and well-informed. You often help people to solve problems and answer questions, and people gain valuable information from your answers, which have a great impact on their lives and work."
    if not user_prompt:
        user_prompt = "Who won the world series in 2020?"
    if not assistant_prompt:
        assistant_prompt = "The Los Angeles Dodgers won the World Series in 2020."
    if not chatgpt_key:
        chatgpt_key = OPENAI_API_KEY

    if debug:
        print(f"DEBUG: chat_gpt() prompt length: {len(prompt.split())}")

    # Load your API key from an environment variable or secret management service
    openai.api_key = chatgpt_key
    if debug: print(f"DEBUG: {dynamic_model} Ê≠£Âú®Âàõ‰Ωú...")
    response = openai.ChatCompletion.create(
        model=dynamic_model,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
            {"role": "assistant", "content": assistant_prompt},
            {"role": "user", "content": prompt}
        ]
    )

    reply = response['choices'][0]['message']['content']
    reply = reply.strip('\n').strip()

    return reply

def send_msg(message, chat_id, parse_mode='', base_url=telegram_base_url):
    if not message: return
    if not chat_id: return print(f"DEBUG: no chat_id, noly print:\n\n{message}")

    url = base_url + "sendMessage"
    payload = {
        "text": message,
        "parse_mode": parse_mode,
        "disable_web_page_preview": True,
        "disable_notification": True,
        "reply_to_message_id": None,
        "chat_id": chat_id
    }
    headers = {"Accept": "application/json", "Content-Type": "application/json"}

    try: requests.post(url, json=payload, headers=headers)
    except Exception as e: return print(f"ERROR: send_msg() failed for:\n{e}\n\nOriginal message:\n{message}")
    if debug: print(f"DEBUG: send_msg(): {message}")
    return True

def send_audio(audio_path, chat_id, base_url=telegram_base_url):
    if not audio_path or not chat_id: return
    if debug: print(f"DEBUG: send_audio()")

    url = base_url + 'sendAudio'
    # send the audio message to the user
    try:
        with open(audio_path, 'rb') as audio_file:
            requests.post(url, data={'chat_id': chat_id}, files={'audio': audio_file})
    except Exception as e: print(f"ERROR : send_audio() failed : {e}")
    return

def send_img(chat_id, file_path, description='', base_url=telegram_base_url):
    if not file_path or not chat_id: return
    method = "sendPhoto?"
    try: files = {'photo': open(file_path, 'rb')}
    except Exception as e: return print(f"ERROR: send_img() failed for:\n{e}\n\nOriginal message:\n{file_path}\n\nCan't open file.")
    URL = base_url + method + "chat_id=" + str(chat_id) + "&caption=" + description
    r = ''
    try: r = requests.post(URL, files=files)
    except Exception as e: print(f"ERROR : send_img() failed : \n{e}")
    return r

def send_file(chat_id, file_path, description='', base_url=telegram_base_url):
    if not file_path or not chat_id: return
    method = "sendDocument?"
    try: files = {'document': open(file_path, 'rb')}
    except Exception as e: return print(f"ERROR: send_file() failed for:\n{e}\n\nOriginal message:\n{file_path}\n\nCan't open file.")
    URL = base_url + method + "chat_id=" + str(chat_id) + "&caption=" + description
    r = ''
    try: r = requests.post(URL, files=files)
    except Exception as e: print(f"ERROR : send_file() failed : \n{e}")
    return r

def tg_get_file_path(file_id):
    url = telegram_base_url + "getFile"
    payload = { "file_id": file_id}
    headers = {"Accept": "application/json", "Content-Type": "application/json"}
    try:
        response = requests.post(url, json=payload, headers=headers)
        if response.status_code != 200: return
        return response.json()['result']
    except Exception as e: return print(f"ERROR: tg_get_file_path() failed: \n{e}")

def replicate_img_to_caption(file_path):
    if debug: print(f"DEBUG: replicate_img_to_caption()")

    os.environ["REPLICATE_API_TOKEN"] = REPLICATE_KEY

    model = replicate.models.get("salesforce/blip")
    version = model.versions.get("2e1dddc8621f72155f24cf2e0adbde548458d3cab9f00c0139eea840d0ac4746")

    # https://replicate.com/salesforce/blip/versions/2e1dddc8621f72155f24cf2e0adbde548458d3cab9f00c0139eea840d0ac4746#input
    inputs = {'image': open(file_path, "rb"), 'task': "image_captioning"}

    # https://replicate.com/salesforce/blip/versions/2e1dddc8621f72155f24cf2e0adbde548458d3cab9f00c0139eea840d0ac4746#output-schema
    output = ''
    try: output = version.predict(**inputs)
    except: pass
    return output

def convert_mp3_to_wav(mp3_file_path):
    if debug: print(f"DEBUG: convert_mp3_to_wav()")
    wav_file_path = mp3_file_path.replace('.mp3', '.wav')
    # Load the mp3 file
    sound = AudioSegment.from_file(mp3_file_path)
    # Set the parameters for the output WAV file
    sample_width = 2  # 16-bit samples
    frame_rate = 16000  # 16 kHz
    # Convert the sound to a mono (single channel) AudioSegment
    sound = sound.set_channels(1)

    # Export the sound as a WAV file with the specified parameters
    sound.export(wav_file_path, format="wav", parameters=["-f", "wav", "-ac", "1", "-ar", "16000"])
    return wav_file_path

# Using openai whisper api to convert voice to text
def from_voice_to_text(audio_path):
    # Note: you need to be using OpenAI Python v0.27.0 for the code below to work
    if audio_path.endswith('ogg'):
        audio_path_mp3 = audio_path.replace('.ogg', '.mp3')
        command = f"ffmpeg -i {audio_path} {audio_path_mp3}"
        subprocess.run(command, shell=True)
    else: audio_path_mp3 = audio_path
    if debug: print(f"DEBUG: from_voice_to_text() audio_path_mp3: {audio_path_mp3}")

    url = "https://api.openai.com/v1/audio/transcriptions"
    headers = {"Authorization": f"Bearer {OPENAI_API_KEY}"}
    data = {
        'model': 'whisper-1',
    }
    with open(audio_path_mp3, 'rb') as f: 
        files = {'file': f}
        response = requests.post(url, headers=headers, data=data, files=files)

    if response.status_code != 200:
        raise Exception(f"Request to OpenAI failed with status {response.status_code}, {response.text}")
    '''
    {
    "text": "Imagine the wildest idea that you've ever had, and you're curious about how it might scale to something that's a 100, a 1,000 times bigger. This is a place where you can get to do that."
    }
    '''
    return response.json().get('text')

def from_voice_to_text_azure(audio_file_path):
    wave_file_path = convert_mp3_to_wav(audio_file_path)

    speech_config = speechsdk.SpeechConfig(subscription=os.getenv('SPEECH_KEY'), region=os.getenv('SPEECH_REGION'))
    audio_config = speechsdk.AudioConfig(filename=wave_file_path)
    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)
    result = speech_recognizer.recognize_once_async().get()
    return result.text

def deal_with_voice_to_text(file_id, file_unique_id):
    if debug: print(f"DEBUG: deal_with_voice_to_text()")
    text = ''  # Create an empty text
    # Create local file name to store voice telegram message
    local_file_folder_name = f"files/audio/{file_unique_id}.ogg"
    # Get the file path of the voice message using the Telegram Bot API
    file_path_url = f"https://api.telegram.org/bot{TELEGRAM_BOT_RUNNING}/getFile?file_id={file_id}"
    try: file_path_response = requests.get(file_path_url).json()
    except Exception as e: return print(f"ERROR: deal_with_voice_to_text() download failed: \n{e}")

    file_path = file_path_response["result"]["file_path"]
    # Download the voice message to your Ubuntu folder
    voice_message_url = f"https://api.telegram.org/file/bot{TELEGRAM_BOT_RUNNING}/{file_path}"
    try:
        with open(local_file_folder_name, "wb") as f:
            response = requests.get(voice_message_url)
            f.write(response.content)
        text = from_voice_to_text(local_file_folder_name)
        if text: return text
    except Exception as e:  print(f"ERROR: from_voice_to_text() 2 FAILED of: \n\n{e}")
    return

def create_midjourney_prompt(prompt):

    system_prompt = midjourney_prompt_fomula if 'fomula' in prompt else midjourney_prompt_1
    prompt = prompt.replace('fomula', '').strip()

    try: beautiful_midjourney_prompt = chat_gpt_full(prompt, system_prompt, midjourney_user_prompt_fomula, midjourney_assistant_prompt_fomula, dynamic_model=OPENAI_MODEL, chatgpt_key=OPENAI_API_KEY)
    except Exception as e:
        print(f"ERROR: create_midjourney_prompt() failed with error: \n{e}")
        return

    return beautiful_midjourney_prompt

def stability_generate_image(text_prompts, cfg_scale=7, clip_guidance_preset="FAST_BLUE", height=512, width=512, samples=1, steps=30, engine_id="stable-diffusion-xl-beta-v2-2-2"):
    response = requests.post(
        f"{STABILITY_URL}generation/{engine_id}/text-to-image",
        headers={
            "Content-Type": "application/json",
            "Accept": "application/json",
            "Authorization": f"Bearer {STABILITY_API_KEY}"
        },
        json={
            "text_prompts": [
                {
                    "text": text_prompts
                }
            ],
            "cfg_scale": cfg_scale,
            "clip_guidance_preset": clip_guidance_preset,
            "height": height,
            "width": width,
            "samples": samples,
            "steps": steps
        }
    )

    if response.status_code != 200:
        raise Exception("Non-200 response: " + str(response.text))

    data = response.json()
    file_path_list = []
    working_folder = 'files/images/dream_studio/'
    if not os.path.exists(working_folder): os.makedirs(working_folder)

    for i, image in enumerate(data["artifacts"]):

        current_timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        filename = hashlib.md5(
            (text_prompts+'_'+str(i)+'_'+str(current_timestamp)).encode()).hexdigest()
        filename_txt = filename + '.txt'
        filename_pic = filename + '.png'
        filepath_txt = f'{working_folder}/{filename_txt}'
        filepath_pic = f'{working_folder}/{filename_pic}'

        with open(filepath_pic, "wb") as f:
            f.write(base64.b64decode(image["base64"]))
            file_path_list.append(filepath_pic)

        with open(filepath_txt, 'w') as f:
            f.write('\n'.join([str(i), text_prompts, current_timestamp, filename,
                    filepath_txt, filepath_pic]))

    return file_path_list

def st_find_ranks_for_word(key_word):
    df = pd.read_sql_query(f'SELECT * FROM db_daily_words WHERE word = "{key_word}"', engine)
    if df.empty: return 
    word_dict = df.iloc[0].to_dict()
    return word_dict

def chat_gpt_english(prompt):
    if not prompt: return

    try:
        if debug: print(f"DEBUG: {OPENAI_MODEL} Amy the English teacher is working length: {len(prompt.split())}...")
        response = openai.ChatCompletion.create(
            model=OPENAI_MODEL,
            messages=[
                {"role": "system", "content": english_system_prompt},
                {"role": "user", "content": english_user_prompt},
                {"role": "assistant", "content": english_assistant_prompt},
                {"role": "user", "content": 'Vector database technology has continued to improve, offering better performance and more personalized user experiences for customers.'},
                {"role": "assistant", "content": '/Ëã±ËØë‰∏≠:\nÁü¢ÈáèÊï∞ÊçÆÂ∫ìÊäÄÊúØ‰∏ÄÁõ¥Âú®‰∏çÊñ≠ÊîπËøõÔºå‰∏∫ÂÆ¢Êà∑Êèê‰æõÊõ¥‰Ω≥ÁöÑÊÄßËÉΩÂíåÊõ¥‰∏™ÊÄßÂåñÁöÑÁî®Êà∑‰ΩìÈ™å„ÄÇ'},
                {"role": "user", "content": '''To address the challenges of digital intelligance in digital economy, artificial intelligence generate content (AIGC) has emerge. AIGC use artificial intalligence to assist or replace manual content generation by generating content based on userinputted keywords or requirements. '''},
                {"role": "assistant", "content": '''
Ëã±ËØë‰∏≠:
‰∏∫‰∫ÜÂ∫îÂØπÊï∞Â≠óÁªèÊµé‰∏≠ÁöÑÊï∞Â≠óÊô∫ËÉΩÊåëÊàòÔºå‰∫∫Â∑•Êô∫ËÉΩÁîüÊàêÂÜÖÂÆπÔºàAIGCÔºâÂ∑≤ÁªèÊ∂åÁé∞„ÄÇAIGCÂà©Áî®‰∫∫Â∑•Êô∫ËÉΩÊù•ËæÖÂä©ÊàñÂèñ‰ª£‰∫∫Â∑•ÂÜÖÂÆπÁîüÊàêÔºåÈÄöËøáÂü∫‰∫éÁî®Êà∑ËæìÂÖ•ÁöÑÂÖ≥ÈîÆËØçÊàñÈúÄÊ±ÇÊù•ÁîüÊàêÂÜÖÂÆπ„ÄÇ

Ëã±Êñá‰∏≠ÁöÑ‰øÆÊîπÂª∫ËÆÆÔºö
"digital intelligance" Â∫îÊîπ‰∏∫ "digital intelligence"
"intalligence" Â∫îÊîπ‰∏∫ "intelligence"
"userinputted" Â∫îÊîπ‰∏∫ "user-inputted"
"has emerge." Â∫îÊîπ‰∏∫ "has emerged"

‰øÆÊîπÂêéÁöÑËã±ÊñáÂè•Â≠êÔºö
To address the challenges of digital intelligence in the digital economy, artificial intelligence generated content (AIGC) has emerged. AIGC uses artificial intelligence to assist or replace manual content generation by generating content based on user-inputted keywords or requirements. '''},
                {"role": "user", "content": '''vector database'''},
                {"role": "assistant", "content": '''
Vector DatabaseÔºàÁü¢ÈáèÊï∞ÊçÆÂ∫ìÔºâ

Èáä‰πâ:
Áü¢ÈáèÊï∞ÊçÆÂ∫ìÊòØ‰∏ÄÁßçÂú∞ÁêÜ‰ø°ÊÅØÁ≥ªÁªüÔºàGISÔºâÊï∞ÊçÆÂ∫ìÔºåÁî®‰∫éÂ≠òÂÇ®„ÄÅÁÆ°ÁêÜÂíåÊü•ËØ¢Âú∞ÁêÜÁ©∫Èó¥Êï∞ÊçÆ‰∏≠ÁöÑÁü¢ÈáèÊï∞ÊçÆ„ÄÇÁü¢ÈáèÊï∞ÊçÆÊòØÁî±ÁÇπ„ÄÅÁ∫øÂíåÂ§öËæπÂΩ¢ÁªÑÊàêÁöÑÂú∞ÁêÜË¶ÅÁ¥†ÔºåÁî®‰ª•Ë°®Á§∫Áé∞ÂÆû‰∏ñÁïå‰∏≠ÁöÑÂú∞ÁêÜ‰ΩçÁΩÆ„ÄÅÂΩ¢Áä∂ÂíåÂ±ûÊÄß„ÄÇ

Áõ∏ÂÖ≥‰ø°ÊÅØ:
‰∏éÁü¢ÈáèÊï∞ÊçÆÂ∫ìÁõ∏ÂØπÁöÑÊòØÊ†ÖÊ†ºÊï∞ÊçÆÂ∫ìÔºåÊ†ÖÊ†ºÊï∞ÊçÆÂ∫ìÁî®‰∫éÂ≠òÂÇ®Ê†ÖÊ†ºÊï∞ÊçÆÔºàÂÉèÁ¥†ÂåñÁöÑÊï∞ÊçÆÔºâÔºåÂ¶ÇÈÅ•ÊÑüÂõæÂÉè„ÄÅÊï∞Â≠óÈ´òÁ®ãÊ®°ÂûãÁ≠â„ÄÇÁü¢ÈáèÊï∞ÊçÆÂ∫ìÊõ¥ÈÄÇÁî®‰∫éË°®Á§∫ÂÖ∑ÊúâÊ∏ÖÊô∞ËæπÁïåÁöÑÂú∞ÁêÜÁâπÂæÅÔºåÂ¶ÇÈÅìË∑Ø„ÄÅÂª∫Á≠ëÁâ©ÂíåË°åÊîøÂå∫ÂàíÔºåËÄåÊ†ÖÊ†ºÊï∞ÊçÆÂ∫ìÈÄÇÁî®‰∫éË°®Á§∫ÊúâËøûÁª≠ÂèòÂåñÁöÑÂú∞ÁêÜÊï∞ÊçÆÔºåÂ¶ÇÊ∞îÂÄôÂíåÊ§çË¢´Á≠â„ÄÇ'''},
                {"role": "user", "content": '''LLaMA'''},
                {"role": "assistant", "content": '''
LLaMA stands for "Large Language Model Assistant." It refers to an AI language model, like ChatGPT, which is designed to assist users with various tasks by generating human-like text based on the input provided. These large language models can be used for answering questions, providing explanations, generating content, and more.

LLaMA ÊòØ "Large Language Model AssistantÔºàÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂä©ÊâãÔºâ" ÁöÑÁº©ÂÜô„ÄÇÂÆÉÊåáÁöÑÊòØÂÉè ChatGPT ËøôÊ†∑ÁöÑ‰∫∫Â∑•Êô∫ËÉΩËØ≠Ë®ÄÊ®°ÂûãÔºåÊó®Âú®ÈÄöËøáÊ†πÊçÆÊèê‰æõÁöÑËæìÂÖ•ÁîüÊàêÁ±ª‰ºº‰∫∫Á±ªÁöÑÊñáÊú¨Êù•ÂçèÂä©Áî®Êà∑ÂÆåÊàêÂêÑÁßç‰ªªÂä°„ÄÇËøô‰∫õÂ§ßÂûãËØ≠Ë®ÄÊ®°ÂûãÂèØÁî®‰∫éÂõûÁ≠îÈóÆÈ¢ò„ÄÅÊèê‰æõËß£Èáä„ÄÅÁîüÊàêÂÜÖÂÆπÁ≠â„ÄÇ
'''},
                {"role": "user", "content": prompt},
                ]
            )
        reply = response['choices'][0]['message']['content']
        reply = reply.strip('\n').strip()
        return reply
    
    except Exception as e: print(f"DEBUG: Amy the English teacher length: {len(prompt.split())} ERROR: \n\n{e}")
    
    return 

'''
    class UserPriority(Base):
        __tablename__ = 'avatar_user_priority'

        id = Column(Integer, primary_key=True, autoincrement=True)
        user_from_id = Column(String(255), unique=True)
        priority = Column(Integer, default=0)
        is_blacklist = Column(Integer, default=0)
        free_until = Column(DateTime, default=datetime.now())
        is_admin = Column(Integer, default=0)
        is_owner = Column(Integer, default=0)
        is_vip = Column(Integer, default=0)
        is_paid = Column(Integer, default=0)
        is_active = Column(Integer, default=0)
        is_deleted = Column(Integer, default=0)
        update_time = Column(DateTime, default=datetime.now())
        next_payment_time = Column(DateTime, default=datetime.now())
        '''

# Mark user is_paid
def mark_user_is_paid(from_id, next_payment_time):
    if not from_id: return
    with Session() as session:
        # Â¶ÇÊûú fronm_id ‰∏çÂ≠òÂú®‰∫éË°®‰∏≠ÔºåÂàôÊèíÂÖ•Êñ∞ÁöÑÊï∞ÊçÆÔºõÂ¶ÇÊûúÂ∑≤ÁªèÂ≠òÂú®ÔºåÂàôÊõ¥Êñ∞Êï∞ÊçÆ
        user_exists = session.query(exists().where(UserPriority.user_from_id == from_id)).scalar()
        if not user_exists:
            new_user = UserPriority(user_from_id=from_id, is_paid=1, next_payment_time=next_payment_time)
            session.add(new_user)
            session.commit()
            print(f"DEBUG: mark_user_is_paid() {from_id} Â∑≤ÁªèÊèíÂÖ•Âà∞ avatar_user_priority Ë°®‰∏≠, is_paid = 1, next_payment_time = {next_payment_time}")
            return True
        session.query(UserPriority).filter(UserPriority.user_from_id == from_id).update({"is_paid": 1, "next_payment_time": next_payment_time})
        session.commit()
        print(f"DEBUG: mark_user_is_paid() {from_id} Â∑≤ÁªèÊõ¥Êñ∞Âà∞ avatar_user_priority Ë°®‰∏≠, is_paid = 1, next_payment_time = {next_payment_time}")
        return True

# Mark user is not paid
def mark_user_is_not_paid(from_id):
    if not from_id: return
    with Session() as session:
        # Â¶ÇÊûú from_id ‰∏çÂ≠òÂú®‰∫éË°®‰∏≠ÔºåÂàôÊèíÂÖ•Êñ∞ÁöÑÊï∞ÊçÆÔºõÂ¶ÇÊûúÂ∑≤ÁªèÂ≠òÂú®ÔºåÂàôÊõ¥Êñ∞Êï∞ÊçÆ
        user_exists = session.query(exists().where(UserPriority.user_from_id == from_id)).scalar()
        if not user_exists:
            new_user = UserPriority(user_from_id=from_id, is_paid=0)
            session.add(new_user)
            session.commit()
            print(f"DEBUG: mark_user_is_not_paid() {from_id} Â∑≤ÁªèÊèíÂÖ•Âà∞ avatar_user_priority Ë°®‰∏≠, is_paid = 0")
            return True
        session.query(UserPriority).filter(UserPriority.user_from_id == from_id).update({"is_paid": 0})
        session.commit()
        print(f"DEBUG: mark_user_is_not_paid() {from_id} Â∑≤ÁªèÊõ¥Êñ∞Âà∞ avatar_user_priority Ë°®‰∏≠, is_paid = 0")
        return True

# ‰ªé UserPriority Ë°®‰∏≠Êü•ËØ¢ÁªôÂÆö from_id ÁöÑÁî®Êà∑ÁöÑ‰ºòÂÖàÁ∫ß, ËøîÂõû‰∏Ä‰∏™Â≠óÂÖ∏
def get_user_priority(from_id):
    if not from_id: return
    user_priority = {}
    try: user_priority = pd.read_sql_query(f'SELECT * FROM avatar_user_priority WHERE user_from_id = "{from_id}"', engine).iloc[0].to_dict()
    except Exception as e: print(f"ERROR: get_user_priority() failed: \n{e}")
    return user_priority

# ‰ªé Coinmarketcap Êü•ËØ¢ÁªôÂÆö token ÁöÑ cmc_rank„ÄÅprice„ÄÅmarket_cap„ÄÅvolume_24h„ÄÅ percent_change_24h„ÄÅmarket_cap„ÄÅfully_diluted_market_cap„ÄÅcirculating_supply„ÄÅtotal_supply„ÄÅlast_updated Á≠âÊï∞ÊçÆ, ËøîÂõû‰∏Ä‰∏™Â≠óÂÖ∏
def get_token_info_from_coinmarketcap_output_chinese(token_symbol):
    token_info = get_token_info_from_coinmarketcap(token_symbol)
    if not token_info: return {}
    output_dict = {
        'ÂêçÁß∞': token_info['name'],
        'ÊéíÂêç': token_info['cmc_rank'],
        'Áé∞‰ª∑': f"{format_number(token_info['quote']['USD']['price'])} usd/{token_symbol.lower()}",
        '‰∫§ÊòìÈáè': f"{format_number(token_info['quote']['USD']['volume_24h'])} usd",
        'ÊµÅÈÄöÂ∏ÇÂÄº': f"{format_number(token_info['quote']['USD']['market_cap'])} usd | {token_info['circulating_supply'] / token_info['total_supply'] * 100:.1f}%",
        '24Â∞èÊó∂Ê≥¢Âä®': f"{token_info['quote']['USD']['percent_change_24h']:.2f}%",
        'ÂÖ®ÊµÅÈÄöÂ∏ÇÂÄº': f"{format_number(token_info['quote']['USD']['fully_diluted_market_cap'])} usd",
        '‰ª£Â∏ÅÊÄªÂèëË°å': f"{format_number(token_info['total_supply'])} {token_symbol.lower()}",
        'Êú¨Ê¨°Êõ¥Êñ∞Êó∂Èó¥': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    }
    # Áî® '\n' join k: v
    output_dict_str = '\n'.join([f"{k}: {v}" for k, v in output_dict.items()])
    return output_dict_str

# Âà§Êñ≠ËæìÂÖ•ÁöÑ hash_tx ÊòØÂê¶Â∑≤ÁªèÂ≠òÂú® avatar_crypto_payments Ë°®‰∏≠ÔºåÂ¶ÇÊûú‰∏çÂ≠òÂú®ÔºåÂàôÊèíÂÖ•Âà∞Ë°®‰∏≠
def insert_into_avatar_crypto_payments(from_id, coin, to_address, value, timestamp, hash_tx, user_title):
    if debug: print(f"DEBUG: insert_into_avatar_crypto_payments()")
    hash_tx = hash_tx.lower()
    coin = coin.upper()
    if coin not in ['USDT', 'USDC']: return
    # Â¶ÇÊûú value Â∞è‰∫é 1 ÂàôËøîÂõû
    value = float(value)
    if value == 0:
        # ÂÖàÂ∞Ü hash_tx Êï∞ÊçÆÊèíÂÖ•Ë°®‰∏≠Ôºå‰ª•ÂêéÂÜçÊù•Êõ¥Êñ∞ value Êï∞ÊçÆ
        with Session() as session:
            # Query the table 'avatar_crypto_payments' to check if the hash_tx exists
            hash_tx_exists = session.query(exists().where(CryptoPayments.Hash_id == hash_tx)).scalar()
            if hash_tx_exists: 
                print(f"DEBUG: hash_tx {hash_tx} Â∑≤ÁªèÂ≠òÂú®‰∫é avatar_crypto_payments Ë°®‰∏≠, ‰ΩÜÊòØ value ‰∏∫ 0, ‰∏çÈúÄË¶ÅÊõ¥Êñ∞!")
                return

            update_time = datetime.strptime(timestamp, "%Y-%m-%dT%H:%M:%S.%fZ")
            new_crypto_payment = CryptoPayments(user_from_id=from_id, address=to_address, usdt_paid_in=0, usdc_paid_in=0, update_time=update_time, Hash_id=hash_tx)
            session.add(new_crypto_payment)
            session.commit()
            print(f"DEBUG: hash_tx {hash_tx} Â∑≤ÁªèÊèíÂÖ•Âà∞ avatar_crypto_payments Ë°®‰∏≠, value ‰∏∫ 0, ÈúÄË¶Å‰∏ãÊ¨°Êõ¥Êñ∞!")
            send_msg(f"‰∫≤Áà±ÁöÑ, ‰Ω†ÁöÑ‰∫§Êòì Transaction Hash {markdown_transaction_hash(hash_tx)} Â∑≤ÁªèÁ≥ªÁªüË¢´ËÆ∞ÂΩï‰∏ãÊù•‰∫Ü, ‰ΩÜÊòØÈìæ‰∏äËøòÊ≤°ÊúâÁ°ÆËÆ§ÊàêÂäü, ËØ∑ËøáÂá†ÂàÜÈíüÁ≠â‰∏ã‰Ω†ÂÜçÁÇπÂáª /check_payment ËØïËØïÁúã, Ë∞¢Ë∞¢‰∫≤! Â¶ÇÊûúÁ≥ªÁªüÊü•Âà∞Èìæ‰∏äÂ∑≤Á°ÆËÆ§, ‰Ω†Â∞±‰∏ç‰ºöÊî∂Âà∞ËøôÊù°Ê∂àÊÅØ‰∫Ü„ÄÇ\n\nÂ¶ÇÊûú‰Ω†ÁúãÂà∞Èìæ‰∏äÁ°ÆËÆ§ÊàêÂäü‰∫Ü, ‰ΩÜÊòØÁ≠â‰∫ÜÂ§™‰πÖÊàëÈÉΩÊ≤°ÊúâÁªô‰Ω†Á°ÆËÆ§ÔºåÊàñËÄÖ‰Ω†ÊÄªÊòØÊî∂Âà∞ËøôÊù°Ê∂àÊÅØÔºåËØ∑ËÅîÁ≥ª {TELEGRAM_USERNAME} ÊâãÂä®Â∏Æ‰Ω†Êü•ÁúãÊòØÂê¶Âà∞Ë¥¶, È∫ªÁÉ¶‰∫≤Áà±ÁöÑ‰∫Ü„ÄÇüòó", from_id, parse_mode='Markdown')
        return 
    
    else:
        # Create a new session
        with Session() as session:
            # Query the table 'avatar_crypto_payments' to check if the hash_tx exists
            hash_tx_exists = session.query(exists().where(CryptoPayments.Hash_id == hash_tx)).scalar()
            if hash_tx_exists: 
                # Âà§Êñ≠ usdt_paid_in Âíå usdc_paid_in ÊòØÂê¶Â∑≤ÁªèÂ≠òÂú®, Âπ∂‰∏îÊúâ‰∏Ä‰∏™Á≠â‰∫é value, Â¶ÇÊûúÊòØÂàôËøîÂõû
                crypto_payment = session.query(CryptoPayments).filter(CryptoPayments.Hash_id == hash_tx).first()
                if crypto_payment.usdt_paid_in == value or crypto_payment.usdc_paid_in == value: 
                    print(f"DEBUG: hash_tx {hash_tx} Â∑≤ÁªèÂ≠òÂú®‰∫é avatar_crypto_payments Ë°®‰∏≠, ‰∏îËÆ∞ÂΩïÁöÑ value ÂíåÊñ∞ËæìÂÖ•ÁöÑ value Áõ∏Á≠â: {value}, ‰∏çÈúÄË¶ÅÊõ¥Êñ∞!")
                    return
                else:
                    # Â¶ÇÊûú usdt_paid_in Âíå usdc_paid_in ÈÉΩ‰∏çÁ≠â‰∫é value, ÂàôÊõ¥Êñ∞ usdt_paid_in Êàñ usdc_paid_in
                    if coin == 'USDT': session.query(CryptoPayments).filter(CryptoPayments.Hash_id == hash_tx).update({CryptoPayments.usdt_paid_in: value})
                    if coin == 'USDC': session.query(CryptoPayments).filter(CryptoPayments.Hash_id == hash_tx).update({CryptoPayments.usdc_paid_in: value})
                    print(f"DEBUG: hash_tx {hash_tx} Â∑≤ÁªèÂ≠òÂú®‰∫é avatar_crypto_payments Ë°®‰∏≠, ‰ΩÜÊòØËÆ∞ÂΩïÁöÑ value ÂíåÊñ∞ËæìÂÖ•ÁöÑ value ‰∏çÁõ∏Á≠â: {value}, Ë°®ÂçïÂ∑≤ÁªèÊõ¥Êñ∞!")
            else:
                update_time = datetime.strptime(timestamp, "%Y-%m-%dT%H:%M:%S.%fZ")
                # Insert the hash_tx into the table 'avatar_crypto_payments'
                usdt_paid_in = value if coin == 'USDT' else 0
                usdc_paid_in = value if coin == 'USDC' else 0

                new_crypto_payment = CryptoPayments(user_from_id=from_id, address=to_address, usdt_paid_in=usdt_paid_in, usdc_paid_in=usdc_paid_in, update_time=update_time, Hash_id=hash_tx)
                session.add(new_crypto_payment)
                session.commit()
                print(f"DEBUG: hash_tx {hash_tx} Â∑≤ÁªèÊèíÂÖ•Âà∞ avatar_crypto_payments Ë°®‰∏≠, value ‰∏∫ {value}, Êõ¥Êñ∞ÂÆåÊØï!")

            next_payment_time = update_time + timedelta(days=(value / MONTHLY_FEE) * 31)
            if next_payment_time < datetime.now(): 
                mark_user_is_not_paid(from_id)
                return

            elif mark_user_is_paid(from_id, next_payment_time):
                send_msg(f"ÂèÆÂíö, {user_title} {from_id} ÂàöÂàöÂà∞Ë¥¶ÂÖÖÂÄº {format_number(value)} {coin.lower()}\n\nÂÖÖÂÄºÂú∞ÂùÄ: \n{markdown_wallet_address(to_address)}\n\n‰∫§ÊòìÂìàÂ∏å:\n{markdown_transaction_hash(hash_tx)}", BOTOWNER_CHAT_ID, parse_mode='Markdown')
                send_msg(f"‰∫≤Áà±ÁöÑ, ‰Ω†‰∫§Êù•ÁöÑÂÖ¨Á≤ÆÂ§üÊàë‰∏ÄÈòµÂ≠êÂï¶ üòçüòçüòç, ‰∏ãÊ¨°‰∫§ÂÖ¨Á≤ÆÁöÑÊó∂Èó¥ÊòØ: \n\n{next_payment_time} \n\n‰Ω†ÂèØÂà´Âøò‰∫ÜÂì¶, ÂèçÊ≠£Âà∞Êó∂ÂÄôÊàë‰ºöÊèêÈÜí‰Ω†Âìí, ‰πà‰πàÂìí üòò", from_id)
            
                next_payment_time_dict = {'last_paid_usd_value': value, 'last_paid_time': update_time, 'next_payment_time': next_payment_time}
                return next_payment_time_dict
    return

def check_incoming_transactions(wallet_address, token_address, chat_id, start_date=None):

    token_address = web3.to_checksum_address(token_address)
    wallet_address = web3.to_checksum_address(wallet_address)

    # ‰ªé CmcTotalSupply db_cmc_total_supply ËØªÂèñ token_address ÁöÑ‰ø°ÊÅØ
    coin_list_df = get_token_info_from_db_cmc_total_supply(token_address)
    if coin_list_df.empty: 
        send_msg(f"Êä±Ê≠â, {token_address} ‰∏çÂú®ÊàëÁöÑÊï∞ÊçÆÂ∫ìÈáå, ‰∏çÊ∏ÖÊ•öËøôÊòØ‰∏™‰ªÄ‰πàÂ∏ÅÂ≠ê, Êó†Ê≥ïÊü•ËØ¢. üò∞", chat_id)
        return
    
    token_address = coin_list_df.iloc[0]['token_address']
    imple_address = coin_list_df.iloc[0]['imple_address']
    coin = coin_list_df.iloc[0]['symbol']
    decimals = int(coin_list_df.iloc[0]['decimals'])

    # Dealing with erc20_symbol and ABI
    ABI = get_token_abi(imple_address)
    
    # Create a contract instance for the ERC20 token
    token_contract = web3.eth.contract(address=token_address, abi=ABI)
    
    if start_date: start_timestamp = int(datetime.strptime(start_date, '%Y-%m-%d').timestamp())
    else: start_timestamp = int(datetime.now().timestamp())

    # Get the latest block number
    latest_block_number = web3.eth.block_number
    
    transactions = []
    # Iterate through each block from the latest to the earliest
    for block_number in range(latest_block_number):
        print(f'DEBUG: checking block_number: {block_number} / {latest_block_number}')
        block = web3.eth.get_block(block_number, full_transactions=True)
        for transaction in block.transactions:
            if transaction['to'] == wallet_address and transaction['input'] != '0x':
                tx_receipt = web3.eth.get_transaction_receipt(transaction['hash'])
                contract_address = tx_receipt['to']
                if contract_address.lower() == '0xtoken_contract_address'.lower():
                    input_data = transaction['input']
                    method_id = input_data[:10]
                    if method_id.lower() == '0xa9059cbb':  # Transfer method ID
                        token_address = '0x' + input_data[34:74]
                        if token_address.lower() == wallet_address.lower():
                            token_amount = int(input_data[74:], 16) / 10 ** 18
                            token_symbol = token_contract.functions.symbol().call()
                            if token_symbol.lower() == coin.lower() and block.timestamp >= start_timestamp:
                                transactions.append({
                                    'token_amount': token_amount,
                                    'block_number': block_number,
                                    'from_address': transaction['from'],
                                    'block_timestamp': block.timestamp,
                                    'transaction_hash': transaction['hash']
                                })
    
    return transactions


def get_internal_transactions(transaction_hash):
    url = f"https://deep-index.moralis.io/api/v2/transaction/{transaction_hash}/internal-transactions?chain=eth"
    headers = {
        "accept": "application/json",
        "X-API-Key": MORALIS_API
    }

    response = requests.get(url, headers=headers)
    if response.status_code == 200:
        return response.json()
    else:
        # Handle error case
        return None

''' return from get_internal_transactions()
[
    {
        "transaction_hash": "0x4916b179936f2a9cd9d65a3433b32ece96bfbe5cad81951763b20d366bbfc1fd",
        "block_number": 17163179,
        "block_hash": "0x2bf2019595a5b551820d28a045c0b533479689f4851ce60d7a6f4bd825947544",
        "type": "CALL",
        "from": "0xa4994144a9217e3779bda588798eff546b69defb",
        "to": "0xdac17f958d2ee523a2206206994597c13d831ec7",
        "value": "0",
        "gas": "523700",
        "gas_used": "29724",
        "input": "0x23b872dd0000000000000000000000001308e4e09ecdeea174a7e160e74da8dda41d1da2000000000000000000000000f1837f9d36e2052496d0983ade9fdb4855d29aa6000000000000000000000000000000000000000000000000000000000bebc200",
        "output": ""
    },
    {
        "transaction_hash": "0x4916b179936f2a9cd9d65a3433b32ece96bfbe5cad81951763b20d366bbfc1fd",
        "block_number": 17163179,
        "block_hash": "0x2bf2019595a5b551820d28a045c0b533479689f4851ce60d7a6f4bd825947544",
        "type": "CALL",
        "from": "0xa4994144a9217e3779bda588798eff546b69defb",
        "to": "0xdac17f958d2ee523a2206206994597c13d831ec7",
        "value": "0",
        "gas": "493825",
        "gas_used": "27224",
        "input": "0x23b872dd0000000000000000000000001308e4e09ecdeea174a7e160e74da8dda41d1da200000000000000000000000066e1ccd77ff59bd17379c895a2320ad0d8c7f127000000000000000000000000000000000000000000000000000000001dcd6500",
        "output": ""
    },
    {
        "transaction_hash": "0x4916b179936f2a9cd9d65a3433b32ece96bfbe5cad81951763b20d366bbfc1fd",
        "block_number": 17163179,
        "block_hash": "0x2bf2019595a5b551820d28a045c0b533479689f4851ce60d7a6f4bd825947544",
        "type": "CALL",
        "from": "0xa4994144a9217e3779bda588798eff546b69defb",
        "to": "0xdac17f958d2ee523a2206206994597c13d831ec7",
        "value": "0",
        "gas": "466411",
        "gas_used": "27224",
        "input": "0x23b872dd0000000000000000000000001308e4e09ecdeea174a7e160e74da8dda41d1da2000000000000000000000000d74b5fdd0d8de1f1345f4d50a76b9303d85c12700000000000000000000000000000000000000000000000000000000013d92d40",
        "output": ""
    },
    {
        "transaction_hash": "0x4916b179936f2a9cd9d65a3433b32ece96bfbe5cad81951763b20d366bbfc1fd",
        "block_number": 17163179,
        "block_hash": "0x2bf2019595a5b551820d28a045c0b533479689f4851ce60d7a6f4bd825947544",
        "type": "CALL",
        "from": "0xa4994144a9217e3779bda588798eff546b69defb",
        "to": "0xdac17f958d2ee523a2206206994597c13d831ec7",
        "value": "0",
        "gas": "438997",
        "gas_used": "10124",
        "input": "0x23b872dd0000000000000000000000001308e4e09ecdeea174a7e160e74da8dda41d1da20000000000000000000000001fe9613aa4d6600bd9133df9c9dc35db80dd74560000000000000000000000000000000000000000000000000000000005f5e100",
        "output": ""
    },
    {
        "transaction_hash": "0x4916b179936f2a9cd9d65a3433b32ece96bfbe5cad81951763b20d366bbfc1fd",
        "block_number": 17163179,
        "block_hash": "0x2bf2019595a5b551820d28a045c0b533479689f4851ce60d7a6f4bd825947544",
        "type": "CALL",
        "from": "0xa4994144a9217e3779bda588798eff546b69defb",
        "to": "0xdac17f958d2ee523a2206206994597c13d831ec7",
        "value": "0",
        "gas": "428416",
        "gas_used": "27224",
        "input": "0x23b872dd0000000000000000000000001308e4e09ecdeea174a7e160e74da8dda41d1da2000000000000000000000000cb95b2cd2fcd8fd98a5d4dd7a618d834f0f66ebc0000000000000000000000000000000000000000000000000000000008954400",
        "output": ""
    },
    {
        "transaction_hash": "0x4916b179936f2a9cd9d65a3433b32ece96bfbe5cad81951763b20d366bbfc1fd",
        "block_number": 17163179,
        "block_hash": "0x2bf2019595a5b551820d28a045c0b533479689f4851ce60d7a6f4bd825947544",
        "type": "CALL",
        "from": "0xa4994144a9217e3779bda588798eff546b69defb",
        "to": "0xdac17f958d2ee523a2206206994597c13d831ec7",
        "value": "0",
        "gas": "401002",
        "gas_used": "10124",
        "input": "0x23b872dd0000000000000000000000001308e4e09ecdeea174a7e160e74da8dda41d1da20000000000000000000000005e278a70193f214c3536fd6f1d298a5eaef5279500000000000000000000000000000000000000000000000000000000ee6b2800",
        "output": ""
    },
    {
        "transaction_hash": "0x4916b179936f2a9cd9d65a3433b32ece96bfbe5cad81951763b20d366bbfc1fd",
        "block_number": 17163179,
        "block_hash": "0x2bf2019595a5b551820d28a045c0b533479689f4851ce60d7a6f4bd825947544",
        "type": "CALL",
        "from": "0xa4994144a9217e3779bda588798eff546b69defb",
        "to": "0xdac17f958d2ee523a2206206994597c13d831ec7",
        "value": "0",
        "gas": "390421",
        "gas_used": "27224",
        "input": "0x23b872dd0000000000000000000000001308e4e09ecdeea174a7e160e74da8dda41d1da2000000000000000000000000946bec3d83ace597d589b5b19dc447ddd69893b800000000000000000000000000000000000000000000000000000000f8e42020",
        "output": ""
    },
    {
        "transaction_hash": "0x4916b179936f2a9cd9d65a3433b32ece96bfbe5cad81951763b20d366bbfc1fd",
        "block_number": 17163179,
        "block_hash": "0x2bf2019595a5b551820d28a045c0b533479689f4851ce60d7a6f4bd825947544",
        "type": "CALL",
        "from": "0xa4994144a9217e3779bda588798eff546b69defb",
        "to": "0xdac17f958d2ee523a2206206994597c13d831ec7",
        "value": "0",
        "gas": "363007",
        "gas_used": "27224",
        "input": "0x23b872dd0000000000000000000000001308e4e09ecdeea174a7e160e74da8dda41d1da20000000000000000000000005fa75f28ca27dad4220e4cf074cff75598fa81300000000000000000000000000000000000000000000000000000000087b64770",
        "output": ""
    },
    {
        "transaction_hash": "0x4916b179936f2a9cd9d65a3433b32ece96bfbe5cad81951763b20d366bbfc1fd",
        "block_number": 17163179,
        "block_hash": "0x2bf2019595a5b551820d28a045c0b533479689f4851ce60d7a6f4bd825947544",
        "type": "CALL",
        "from": "0xa4994144a9217e3779bda588798eff546b69defb",
        "to": "0xdac17f958d2ee523a2206206994597c13d831ec7",
        "value": "0",
        "gas": "335594",
        "gas_used": "27224",
        "input": "0x23b872dd0000000000000000000000001308e4e09ecdeea174a7e160e74da8dda41d1da2000000000000000000000000c46d4d0e6c8fd624b46d73ca88baef2903dbb7160000000000000000000000000000000000000000000000000000000069e89450",
        "output": ""
    }
]
'''

def get_transaction_details(transaction_hash, chain='eth'):
    url = f'https://deep-index.moralis.io/api/v2/transaction/{transaction_hash}?chain={chain}'
    headers = {'accept': 'application/json', 'X-API-Key': MORALIS_API}
    response = requests.get(url, headers=headers)
    # print(response.status_code, response.text)
    if response.status_code == 200:
        return response.json()
    else:
        print(f'Request failed with status code: {response.status_code}')
        return None

''' get_transaction_details() ËøîÂõûÁöÑÊï∞ÊçÆÁªìÊûÑ
{"hash":"0x85f32cce4fb8f21bbe47ee2605cfb61f0832c9a758e7c12d536d05cc2afe9ac5","nonce":"0","transaction_index":"140","from_address":"0x4408d8991d9f4419a53487fe2027223ba5cf2207","to_address":"0xdac17f958d2ee523a2206206994597c13d831ec7","value":"0","gas":"69163","gas_price":"33573951716","input":"0xa9059cbb000000000000000000000000c635eabcf791bc8226ba0a76dce2cae061745bfe00000000000000000000000000000000000000000000000000000012a05f2000","receipt_cumulative_gas_used":"10476207","receipt_gas_used":"46109","receipt_contract_address":null,"receipt_root":null,"receipt_status":"1","block_timestamp":"2023-05-19T05:38:23.000Z","block_number":"17291516","block_hash":"0x4cfb8c2b10460f05a05583df7fa2247b6dccc42852e48dfa22022340245805d8","transfer_index":[17291516,140],"logs":[{"log_index":"274","transaction_hash":"0x85f32cce4fb8f21bbe47ee2605cfb61f0832c9a758e7c12d536d05cc2afe9ac5","transaction_index":"140","transaction_value":"0","address":"0xdac17f958d2ee523a2206206994597c13d831ec7","data":"0x00000000000000000000000000000000000000000000000000000012a05f2000","topic0":"0xddf252ad1be2c89b69c2b068fc378daa952ba7f163c4a11628f55a4df523b3ef","topic1":"0x0000000000000000000000004408d8991d9f4419a53487fe2027223ba5cf2207","topic2":"0x000000000000000000000000c635eabcf791bc8226ba0a76dce2cae061745bfe","topic3":null,"block_timestamp":"2023-05-19T05:38:23.000Z","block_number":"17291516","block_hash":"0x4cfb8c2b10460f05a05583df7fa2247b6dccc42852e48dfa22022340245805d8","transfer_index":[17291516,140,274]}]}'''

# ÈÄöËøá hash_tx Êü•ËØ¢ËΩ¨Ë¥¶‰ø°ÊÅØ
def get_transactions_info_by_hash_tx(hash_tx, chat_id, user_title, chain='eth'):
    hash_tx = str(hash_tx).lower()
    if not hash_tx.startswith('0x') and len(hash_tx) == 64: hash_tx = '0x' + hash_tx
    if len(hash_tx) != 66: 
        return send_msg(f"ËæìÂÖ•ÁöÑ hash_tx ÈïøÂ∫¶‰∏çÂØπ, ËØ∑ÂõûÂ§çÊ≠£Á°ÆÁöÑ Transaction_Hash: 0xÂºÄÂ§¥, ‰∏ÄÂÖ± 66 ‰ΩçÂ≠óÁ¨¶ üòÉ", chat_id)
    trans_info = get_transaction_details(hash_tx, chain=chain)

    if not trans_info: 
        send_msg(f"Êä±Ê≠â, Êó†Ê≥ïÊü•ËØ¢Âà∞ {hash_tx} ÁöÑËΩ¨Ë¥¶‰ø°ÊÅØ, ËØ∑Ê£ÄÊü•ËæìÂÖ•ÊòØÂê¶Ê≠£Á°Æ. üò∞", chat_id)
        return 
    if not trans_info.get('input'): 
        send_msg(f"Êä±Ê≠â, Êü•Âà∞ÁöÑ‰ø°ÊÅØÊúâÈóÆÈ¢ò, Êó†Ê≥ïÊ≠£Á°ÆËØªÂèñ. üò∞", chat_id)
        return 
    if trans_info.get('value') != '0': 

        '''
            {
                "hash": "0x76e669a454257ac506d62ef55b6123b7a6c592b276922aa051eac5b00a9dad97",
                "nonce": "92",
                "transaction_index": "113",
                "from_address": "0x5e278a70193f214c3536fd6f1d298a5eaef52795",
                "to_address": "0x4408d8991d9f4419a53487fe2027223ba5cf2207",
                "value": "7800000000000000000",
                "gas": "21000",
                "gas_price": "16198064885",
                "input": "0x",
                "receipt_cumulative_gas_used": "14258140",
                "receipt_gas_used": "21000",
                "receipt_contract_address": null,
                "receipt_root": null,
                "receipt_status": "1",
                "block_timestamp": "2023-03-24T23:33:11.000Z",
                "block_number": "16900645",
                "block_hash": "0xa9adb1f2efa884db49704aaa4067c52dd8987b454074476f4e6eb0da0b0c2bce",
                "transfer_index": [
                    16900645,
                    113
                ],
                "logs": [],
                "decoded_call": null
            }
            '''

        eth_value = int(trans_info.get('value')) / 1_000_000_000_000_000_000
        send_msg(f"‰∫≤Áà±ÁöÑ, ËøôÊòØ‰∏ÄÁ¨î ETH ËΩ¨Ë¥¶ ü§©:\n\nËΩ¨Ë¥¶Êï∞È¢ù: {format_number(eth_value)} eth\nËΩ¨Ë¥¶Âú∞ÂùÄ: {markdown_wallet_address(trans_info.get('from_address'))}\nÊî∂Ê¨æÂú∞ÂùÄ: {markdown_wallet_address(trans_info.get('to_address'))}\n‰∫§ÊòìÁ°ÆËÆ§: {markdown_transaction_hash(hash_tx)}", chat_id, parse_mode='Markdown', base_url=telegram_base_url)

        return 
    
    token_address = trans_info.get('to_address')
    
    # ‰ªé CmcTotalSupply db_cmc_total_supply ËØªÂèñ token_address ÁöÑ‰ø°ÊÅØ
    coin_list_df = get_token_info_from_db_cmc_total_supply(token_address)
    if coin_list_df.empty: 

        internal_trans_list = get_internal_transactions(hash_tx)
        if type(internal_trans_list) != list: 
            send_msg(f"Êä±Ê≠â, {markdown_token_address(token_address)} ‰∏çÂú®ÊàëÁöÑÊï∞ÊçÆÂ∫ìÈáå, ‰∏çÊ∏ÖÊ•öËøôÊòØ‰∏™‰ªÄ‰πàÂ∏ÅÂ≠ê, Êó†Ê≥ïÊü•ËØ¢. üò∞", chat_id, parse_mode='Markdown')
            return
        # Â∞Ü internal_trans_list ‰øùÂ≠ò‰∏∫ Json Êñá‰ª∂, Âú® files/transactions Êñá‰ª∂Â§π‰∏ã‰øùÂ≠òÊñá‰ª∂, filename=hash_tx.json, Âπ∂Áî® send_file ÂèëÁªôÁî®Êà∑
        file_path = f"files/transactions/{hash_tx}.json"
        with open(file_path, 'w') as f: json.dump(internal_trans_list, f, indent=2)
        send_file(chat_id, file_path)
        send_msg(f"‰∫≤Áà±ÁöÑ, ÂèëÁöÑÁöÑËøô‰∏™ÁúãËµ∑Êù•ÊòØ‰∏Ä‰∏™Êô∫ËÉΩÂêàÁ∫¶‰∫§‰∫íÁöÑËÆ∞ÂΩï, ÊúâÁÇπÂ§çÊùÇ, Êàë‰øùÂ≠ò‰∏ãÊù•ÂèëÁªô‰Ω†ÁúãÁúãÂêß. Êàë‰πüÁúã‰∏çÊòéÁôΩ, Âª∫ËÆÆ‰Ω†ÂèØ‰ª•ÁÇπÂáª‰∏ãÈù¢ÁöÑÈìæÊé•Âéª Etherscan È°µÈù¢‰∏äÁúãÁúã, ÈÇ£ËæπÁöÑËß£ËØªÊ∏ÖÊô∞‰∏ÄÁÇπÂìà üòÖ, Êä±Ê≠âÊàëÂ∏Æ‰∏ç‰∫Ü‰Ω†Âïä, ÊàëËøò‰∏çÂ§üÂéâÂÆ≥, ÊàëËøòË¶ÅÁªßÁª≠Â≠¶‰π†, ÁªßÁª≠Âä™Âäõ„ÄÇ‰∏çË°å‰Ω†ÊääÊñá‰ª∂ÂÜÖÂÆπÊã∑Ë¥ùÈªèË¥¥Áªô ChatGPT, ËÆ©‰ªñÂ∏Æ‰Ω†Ëß£ËØª‰∏Ä‰∏ãËøô‰∏™Êô∫ËÉΩÂêàÁ∫¶ÁöÑ‰∫§‰∫íÊÄé‰πàÂõû‰∫ã, ÊòØ‰ªÄ‰πàÊ†∑ÁöÑ‰∫§‰∫í, ‰∫§ÊòìÈáëÈ¢ùÂ§öÂ§ß„ÄÇ\n\n{markdown_transaction_hash(hash_tx)}", chat_id, parse_mode='Markdown', base_url=telegram_base_url)
        return 
    
    token_address = coin_list_df.iloc[0]['token_address']
    imple_address = coin_list_df.iloc[0]['imple_address']
    coin = coin_list_df.iloc[0]['symbol']
    decimals = int(coin_list_df.iloc[0]['decimals'])
	
    if debug: print(f"DEBUG: ÊâæÂà∞ËæìÂÖ•ÁöÑ HashId ‰∫§ÊòìÁöÑÂ∏ÅÁßçÊòØ: {coin}, decimals: {decimals}")

    # Dealing with erc20_symbol and ABI
    ABI = get_token_abi(imple_address)
    contract = web3.eth.contract(token_address, abi=ABI)
    from_address = trans_info['from_address']
    from_address = web3.to_checksum_address(from_address)
    from_addr_balance_wei = contract.functions.balanceOf(from_address).call()
    from_addr_balance = float(from_addr_balance_wei / 10 ** decimals)
    func_obj, func_params = contract.decode_function_input(trans_info.get('input'))
    '''return : {'to': '0x376FA5C248EECB0110023efADD8317691B07EDe1', 'value': 56195000000}'''
    try:
        func_params['value'] = func_params.get('amount') if 'amount' in func_params else func_params.get('_value') if '_value' in func_params else func_params.get('value')
        func_params['to'] = func_params.get('recipient') if 'recipient' in func_params else func_params.get('_to') if '_to' in func_params else func_params.get('to')
        func_params['value'] = float(float(func_params.get('value')) / (10 ** decimals)) if func_params.get('value') else 0
        func_params['status'] = True if trans_info.get('receipt_status') == '1' else False
        func_params['data'] = trans_info.get('input')
        # func_params['gas_cost'] = float(trans_info['receipt_cumulative_gas_used']) * eth_price * 1_000_000_000
        func_params['from_address'] = from_address
        func_params['from_addr_balance'] = from_addr_balance + func_params['value']
        func_params['token_address'] = token_address
        func_params['decimals'] = decimals
        func_params['coin'] = coin
        func_params['block_timestamp'] = trans_info['block_timestamp']
        to_address = func_params.get('to')
        if chat_id:
            r = {
                'ËΩ¨Ë¥¶ÈÄöËØÅ': coin,
                'ËΩ¨Ë¥¶ÈáëÈ¢ù': format_number(func_params['value']),
                'ÂèëÂá∫Âú∞ÂùÄ': markdown_wallet_address(from_address),
                'ÁõÆÊ†áÂú∞ÂùÄ': markdown_wallet_address(to_address),
                'Á°ÆËÆ§Êó∂Èó¥': ' '.join(str(trans_info['block_timestamp']).split('.')[0].split('T'))
                }
            # Áî® '\n' join k: v from r
            r = '\n'.join([f"{k}: {v}" for k, v in r.items()])
            send_msg(r, chat_id, parse_mode='Markdown')

        # Ê£ÄÊü• to_address ÊòØÂê¶Âú® table avatar_eth_wallet, Â¶ÇÊûúÂú®, ËØ¥ÊòéËøôÊòØÁî®Êà∑ÁöÑÂÖÖÂÄºÂú∞ÂùÄ, ÈúÄË¶ÅÊú¨Ê¨°‰∫§ÊòìÁöÑ‰ø°ÊÅØÂÜôÂÖ• avatar_crypto_payments
        from_id = get_from_id_by_eth_address(to_address)
        if from_id and from_id in [chat_id] + BOT_OWNER_LIST:

            '''func_params:
            {"to": "0x5e278a70193F214C3536FD6f1D298a5eaeF52795", "value": 100.0, "status": true, "data": "0xa9059cbb0000000000000000000000005e278a70193f214c3536fd6f1d298a5eaef527950000000000000000000000000000000000000000000000000000000005f5e100", "from_address": "0xb411B974c0ac75C88E5039ea0bf63a84aa7B5377", "from_addr_balance": 2512.718824, "token_address": "0xA0b86991c6218b36c1d19D4a2e9Eb0cE3606eB48", "decimals": 6, "coin": "USDC", "block_timestamp": "2023-03-11T22:25:59.000Z"}'''

            '''class CryptoPayments(Base):
                    __tablename__ = 'avatar_crypto_payments'

                    id = Column(Integer, primary_key=True, autoincrement=True)
                    user_from_id = Column(String(255))
                    address = Column(String(255))
                    usdt_paid_in = Column(Float, default=0)
                    usdc_paid_in = Column(Float, default=0)
                    eth_paid_in = Column(Float, default=0)
                    update_time = Column(DateTime)
                    Hash_id = Column(Text)
            '''

            # Â∞ÜÊúÄÊñ∞Ëé∑ÂèñÁöÑ‰∫§Êòì‰ø°ÊÅØÂÜôÂÖ• avatar_crypto_payments
            try: 
                func_params['value'] = 0 if not func_params['status'] else func_params['value']
                next_payment_time_dict= insert_into_avatar_crypto_payments(from_id, coin, to_address, func_params['value'], func_params['block_timestamp'], hash_tx, user_title)
            except Exception as e: print(f"ERROR: insert_into_avatar_crypto_payments() failed: \n{e}")
            
        return next_payment_time_dict
    except Exception as e: print('DEBUG: get_transactions_info_by_hash_tx() error: ', e)
    return


# ËÆ°ÁÆóÁî®Êà∑‰∏ãÊ¨°ÈúÄË¶ÅÁª≠Ë¥πÁöÑÊó∂Èó¥ÊòØÂì™Â§©, ËøîÂõû‰∏Ä‰∏™ datetime ÂØπË±°
def update_user_next_payment_date(user_from_id, user_title):
    if debug: print(f"DEBUG: update_user_next_payment_date()")
    # Create a new session
    with Session() as session:
        # Áî® pandas ‰ªéË°®Âçï‰∏≠ËØªÂá∫ from_id ÂØπÂ∫îÊúÄÂêé‰∏ÄÁ¨î crypto payment ÁöÑÊï∞ÊçÆ, Âà§Êñ≠ usdt_paid_in Âíå usdc_paid_in Âì™‰∏™‰∏çÊòØ 0, Âπ∂Â∞Ü‰∏ç‰∏∫Èõ∂ÁöÑ value Âíå update_time ËØªÂá∫‰∏ÄÂπ∂ËøîÂõû
        crypto_payments = session.query(CryptoPayments).filter(CryptoPayments.user_from_id == user_from_id).order_by(CryptoPayments.id.desc()).first()
        if crypto_payments:
            value = crypto_payments.usdt_paid_in if crypto_payments.usdt_paid_in else crypto_payments.usdc_paid_in if crypto_payments.usdc_paid_in else 0
            if value:  
                # ËÆ°ÁÆó‰∏ãÊ¨°‰∏ãÊ¨°Áº¥Ë¥πÊó∂Èó¥
                x = value / MONTHLY_FEE
                next_payment_time = crypto_payments.update_time + timedelta(days=x * 31)
                if next_payment_time > datetime.now():
                    next_payment_time_dict = {'last_paid_usd_value': value, 'last_paid_time': crypto_payments.update_time, 'next_payment_time': next_payment_time}
                    return next_payment_time_dict
            if crypto_payments.Hash_id: return get_transactions_info_by_hash_tx(crypto_payments.Hash_id, user_from_id, user_title, chain='eth')
    return 
    
        

def get_outgoing_transactions_from_address_in_24h(wallet_address):
    url = f"https://deep-index.moralis.io/api/v2/{wallet_address}/verbose"
    
    # Get the date and time 24 hours ago
    from_date = datetime.now() - timedelta(days=1)
    from_date_formatted = datetime.strftime(from_date, "%Y-%m-%dT%H:%M:%S")

    headers = {
        'accept': 'application/json',
        'X-API-Key': MORALIS_API,
    }
    
    params = {
        'chain': 'eth',
        'from_date': from_date_formatted
    }

    response = requests.get(url, headers=headers, params=params)
    
    if response.status_code == 200: return response.json()
    else: return None


def read_outgoing_transaction_in_24h_result(wallet_address):
    result = get_outgoing_transactions_from_address_in_24h(wallet_address)

    transaction_list = []
    
    for transaction in result['result']:
        if not transaction.get('logs'): continue

        decoded_event = transaction['logs'][0]['decoded_event']
        token_address = transaction['logs'][0]['address']
        if token_address.lower() not in [USDT_ERC20.lower(), USDC_ERC20.lower()]: continue

        token_name = 'USDT' if token_address.lower() == USDT_ERC20.lower() else 'USDC'

        transfer_info = {}
        for param in decoded_event['params']:
            transfer_info[param['name']] = param['value']

        timestamp = convert_to_local_timezone(transaction['block_timestamp'])

        transaction_info = {
            'Â∏ÅÁßçÂêçÁß∞': token_name,  # Replace with your function to retrieve the token name
            'ÂèëËµ∑Âú∞ÂùÄ': markdown_wallet_address(transfer_info['from']),
            'Êî∂Â∏ÅÂú∞ÂùÄ': markdown_wallet_address(transfer_info['to']),
            'ËΩ¨Ë¥¶Êï∞Èáè': format_number(int(transfer_info['value']) / (10 ** USDT_ERC20_DECIMALS)),  # Replace with your function to retrieve the token decimals
            'Ë•øÂ≤∏Êó∂Èó¥': timestamp,
        }
        
        transaction_list.append(transaction_info)

    return transaction_list

def read_and_send_24h_outgoing_trans(wallet_address, chat_id):
    # wallet_address = web3.to_checksum_address(wallet_address)
    transaction_list =  read_outgoing_transaction_in_24h_result(wallet_address)
    if not transaction_list: return

    total_transactions_count = len(transaction_list)
    msg_info = f"‰∫≤Áà±ÁöÑ, {wallet_address[:5]}...{wallet_address[-5:]} Èí±ÂåÖÂú∞ÂùÄ 24 Â∞èÊó∂ÂÜÖ‰∏ÄÂÖ±Êúâ {total_transactions_count} Á¨î USDT/USDC ËΩ¨Âá∫ËÆ∞ÂΩïüòç, ÂÄíÂ∫èÊéíÂàóÂ¶Ç‰∏ã: "
    send_msg(msg_info, chat_id)
    if total_transactions_count > 10: transaction_list = transaction_list[:10]
    i = 0
    for transaction in transaction_list:
        i += 1
        r = '\n'.join([f"{k}: {v}" for k, v in transaction.items()])
        send_msg(f"Á¨¨{i}Á¨î:\n{r}", chat_id, parse_mode='Markdown', base_url=telegram_base_url)
    if total_transactions_count > 10: send_msg(f"ËøòÊúâ {total_transactions_count - 10} Á¨îËΩ¨Ë¥¶ËÆ∞ÂΩï, ËØ∑Âà∞ Etherscan ‰∏äÊü•ÁúãÂìà:\n{markdown_wallet_address(wallet_address)}", chat_id, parse_mode='Markdown', base_url=telegram_base_url)
    return

if __name__ == '__main__':
    print(f"tvariables.py is running...")
    if BOTOWNER_CHAT_ID == BOTCREATER_CHAT_ID:
        try: 
            user_title = 'Laogege'
            coin = 'USDT'
            to_address = '0x3E711058491fB0723c6De9fD7E0c1b6635DE4A57'
            hash_tx = '0x109b661b1025c8a2a34c4633e283970608745c0f64d6dc0f0976fb92b18c234e'
            time_stamp = '2023-03-11T22:25:59.000Z'
            value = 20000
            r = insert_into_avatar_crypto_payments(BOTOWNER_CHAT_ID, coin, to_address, value, time_stamp, hash_tx, user_title)
            if r: 
                send_msg(f"ÂèÆÂíö, {user_title} {BOTOWNER_CHAT_ID} ÂàöÂàöÂÖÖÂÄº {format_number(value)} {coin.lower()}\n\nÂÖÖÂÄºÂú∞ÂùÄ: \n{markdown_wallet_address(to_address)}\n\n‰∫§ÊòìÂìàÂ∏å:\n{markdown_transaction_hash(hash_tx)}", BOTOWNER_CHAT_ID, parse_mode='Markdown')
                next_payment_time_dict = update_user_next_payment_date(BOTOWNER_CHAT_ID, user_title)
                send_msg(f"‰∫≤Áà±ÁöÑ, ‰Ω†‰∫§Êù•ÁöÑÂÖ¨Á≤ÆÂ§üÊàë‰∏ÄÈòµÂ≠êÂï¶ üòçüòçüòç, ‰∏ãÊ¨°‰∫§ÂÖ¨Á≤ÆÁöÑÊó∂Èó¥ÊòØ: \n\n{next_payment_time_dict['next_payment_time']} \n\n‰Ω†ÂèØÂà´Âøò‰∫ÜÂì¶, ÂèçÊ≠£Âà∞Êó∂ÂÄôÊàë‰ºöÊèêÈÜí‰Ω†Âìí, ‰πà‰πàÂìí üòò", BOTOWNER_CHAT_ID)
        except Exception as e: print(f"ERROR: insert_into_avatar_crypto_payments() failed: \n{e}")